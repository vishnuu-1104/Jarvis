# Environment Configuration
# Copy this file to .env and fill in your values

# Pinecone Configuration
PINECONE_API_KEY=your_pinecone_api_key_here
PINECONE_ENVIRONMENT=us-east-1
PINECONE_INDEX_NAME=personal-assistant

# Ollama LLM Configuration (self-hosted LLaMA)
# Available models: llama2, llama2:13b, llama2:70b, mistral, codellama, etc.
OLLAMA_MODEL=llama2
OLLAMA_HOST=http://localhost:11434
MAX_TOKENS=2048
TEMPERATURE=0.7

# Embedding Model
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Server Configuration
HOST=0.0.0.0
PORT=8000

# Vector DB Settings
TOP_K_RESULTS=5
SIMILARITY_THRESHOLD=0.7
